name: "🔒 Comprehensive Security Analysis"

permissions:
  contents: read
  security-events: write
  actions: read
  issues: write

on:
  push:
    branches: [ '**' ]
    tags: [ '**' ]
  pull_request:
    branches: [ master ]
  schedule:
    - cron: '0 4 * * *'  # Run at 4 AM UTC daily
  workflow_dispatch:

jobs:
  comprehensive-security:
    name: 🔒 Complete Security Analysis
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'
    
    steps:
      # ============================================================================
      # SETUP & CHECKOUT
      # ============================================================================
      - name: Checkout repository
        uses: actions/checkout@v5.0.0

      # ============================================================================
      # CODEQL STATIC ANALYSIS
      # ============================================================================
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3.30.5
        with:
          languages: javascript
          build-mode: none
          queries: +security-extended,security-and-quality
          config: |
            name: "Advanced Security Configuration"
            queries:
              - uses: security-extended
              - uses: security-and-quality
            paths:
              - root/
              - scripts/
              - .github/
            paths-ignore:
              - "**/*.md"
              - "**/*.txt"
              - "**/*.json"
              - "LICENSE"

      - name: Perform CodeQL Analysis
        id: codeql-analysis
        uses: github/codeql-action/analyze@v3.30.5
        continue-on-error: true
        with:
          category: "/language:javascript"
          upload: true
          # Output SARIF file for inclusion in artifacts
          output: codeql-results.sarif

      # ============================================================================
      # SUPER-LINTER CODE QUALITY
      # ============================================================================
      - name: Run Super-Linter
        id: super-linter
        uses: super-linter/super-linter@v8.1.0
        continue-on-error: true
        env:
          DEFAULT_BRANCH: ${{ github.event.repository.default_branch }}
          GITHUB_TOKEN: ${{ github.token }}
          VALIDATE_ALL_CODEBASE: false
          VALIDATE_DOCKERFILE_HADOLINT: true
          VALIDATE_BASH: true
          VALIDATE_SHELL_SHFMT: true
          VALIDATE_MARKDOWN: true
          VALIDATE_JSON: true
          VALIDATE_YAML: true
          LOG_LEVEL: DEBUG
          CREATE_LOG_FILE: true
          OUTPUT_FORMAT: tap
          OUTPUT_FOLDER: super-linter-logs
          OUTPUT_DETAILS: detailed

      - name: Capture Super-Linter detailed logs
        if: always() && steps.super-linter.outcome == 'failure'
        run: |
          echo "=== Capturing Super-Linter logs ==="
          mkdir -p super-linter-output
          
          # Fix ownership/permissions for the directory
          sudo chown -R runner:docker super-linter-output
          sudo chmod -R 755 super-linter-output
          
          # Verify directory creation and permissions
          if [ ! -d "super-linter-output" ]; then
            echo "❌ Failed to create super-linter-output directory"
            exit 1
          fi
          
          echo "✅ super-linter-output directory created successfully"
          ls -la super-linter-output/ || echo "Directory is empty"
          
          # Capture general logs
          if [ -d "super-linter-logs" ]; then
            echo "Found super-linter-logs directory"
            cp -r super-linter-logs/* super-linter-output/ 2>/dev/null || true
          fi
          
          # Look for common Super-Linter log locations
          for log_path in \
            "/tmp/lint" \
            "/github/workspace/super-linter.log" \
            "/github/workspace/linter-results" \
            "./super-linter.log" \
            "/tmp/super-linter.log" \
            "./super-linter-logs"
          do
            if [ -e "$log_path" ]; then
              echo "Found logs at: $log_path"
              if [ -d "$log_path" ]; then
                cp -r "$log_path"/* super-linter-output/ 2>/dev/null || true
              else
                cp "$log_path" super-linter-output/ 2>/dev/null || true
              fi
            fi
          done
          
          # Create a comprehensive log file with all findings
          echo "Creating summary file..."
          if ! echo "# Super-Linter Results Summary" > super-linter-output/summary.md; then
            echo "❌ Failed to create summary.md file"
            ls -la super-linter-output/
            exit 1
          fi
          
          echo "Generated: $(date)" >> super-linter-output/summary.md
          echo "" >> super-linter-output/summary.md
          
          # Find and process individual linter logs
          find . -name "*.tap" -o -name "*-lint.log" -o -name "super-linter*.log" 2>/dev/null | while read -r file; do
            if [ -f "$file" ] && [ -s "$file" ]; then
              echo "Processing: $file"
              {
                echo "## Log file: $file"
                echo "```"
                cat "$file" 2>/dev/null || echo "Could not read file"
                echo "```"
                echo ""
              } >> super-linter-output/summary.md
            fi
          done
          
          echo "=== Super-Linter logs captured ==="
          ls -la super-linter-output/ || echo "No output directory created"

      # ============================================================================
      # TRIVY VULNERABILITY SCANNING
      # ============================================================================
      - name: Run Trivy filesystem scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3.30.5
        if: always() && hashFiles('trivy-results.sarif') != ''
        continue-on-error: true
        with:
          sarif_file: 'trivy-results.sarif'
          category: 'trivy-filesystem-security'

      - name: Run Trivy on Dockerfile
        id: trivy-config
        uses: aquasecurity/trivy-action@master
        continue-on-error: true
        with:
          scan-type: 'config'
          scan-ref: 'Dockerfile'
          format: 'table'

      # ============================================================================
      # RESULTS COMPILATION & ARTIFACTS
      # ============================================================================
      - name: Create comprehensive scan results
        if: always()
        run: |
          # Create directory for all scan results
          mkdir -p scan-results
          
          # Copy all scan result files if they exist
          [ -f "trivy-results.sarif" ] && cp trivy-results.sarif scan-results/
          [ -f "codeql-results.sarif" ] && cp codeql-results.sarif scan-results/
          
          # Create unified summary
          cat > scan-results/security-analysis-summary.md << 'EOF'
          # 🔒 Comprehensive Security Analysis Report
          EOF
          
          # Add dynamic content
          ANALYSIS_DATE="$(date -u +"%Y-%m-%d %H:%M:%S UTC")"
          REPOSITORY="${{ github.repository }}"
          COMMIT="${{ github.sha }}"
          BRANCH="${{ github.ref_name }}"
          RUN_ID="${{ github.run_id }}"
          CODEQL_STATUS="${{ steps.codeql-analysis.outcome }}"
          SUPERLINTER_STATUS="${{ steps.super-linter.outcome }}"
          TRIVY_CONFIG_STATUS="${{ steps.trivy-config.outcome }}"
          
          cat >> scan-results/security-analysis-summary.md << EOF
          
          **Analysis Date:** ${ANALYSIS_DATE}
          **Repository:** ${REPOSITORY}
          **Commit:** ${COMMIT}
          **Branch:** ${BRANCH}
          **Run ID:** ${RUN_ID}
          
          ## 🔍 Analysis Components
          
          ### 🔬 CodeQL Static Analysis
          - **Status:** ${CODEQL_STATUS}
          - **Language:** JavaScript (with generic security patterns)
          - **Queries:** security-extended + security-and-quality
          - **Scope:** Shell scripts, configs, GitHub Actions workflows
          
          ### 🧹 Super-Linter Code Quality
          - **Status:** ${SUPERLINTER_STATUS}
          - **Languages:** Bash, Dockerfile, Markdown, JSON, YAML
          - **Validation:** Syntax, style, and best practices
          
          ### 🛡️ Trivy Vulnerability Scanning
          - **Config Analysis Status:** ${TRIVY_CONFIG_STATUS}
          - **Scope:** Dependencies, container vulnerabilities, misconfigurations
          
          ## 📊 Summary Statistics
          EOF
          
          # Add Trivy filesystem scan status
          if [ -f "trivy-results.sarif" ]; then
            echo "- **Filesystem Status:** ✅ Completed" >> scan-results/security-analysis-summary.md
          else
            echo "- **Filesystem Status:** ❌ No results" >> scan-results/security-analysis-summary.md
          fi
          
          # Add Trivy results count if available
          if [ -f "trivy-results.sarif" ] && command -v jq >/dev/null 2>&1; then
            TRIVY_COUNT=$(jq '.runs[0].results | length' trivy-results.sarif 2>/dev/null || echo "0")
            echo "- **Trivy Findings:** $TRIVY_COUNT security issues detected" >> scan-results/security-analysis-summary.md
          fi
          
          # Add CodeQL results count if available
          if [ -f "codeql-results.sarif" ] && command -v jq >/dev/null 2>&1; then
            CODEQL_COUNT=$(jq '.runs[0].results | length' codeql-results.sarif 2>/dev/null || echo "0")
            echo "- **CodeQL Findings:** $CODEQL_COUNT security issues detected" >> scan-results/security-analysis-summary.md
          fi
          
          # Add file listing
          cat >> scan-results/security-analysis-summary.md << 'EOF'
          
          ## 📁 Included Files
          EOF
          
          ls -la scan-results/ | grep -v "^total" | grep -v "^d" | awk '{print "- " $9 " (" $5 " bytes)"}' >> scan-results/security-analysis-summary.md
          
          # Add links section
          cat >> scan-results/security-analysis-summary.md << EOF
          
          ## 🔗 View Results
          - [Workflow Run](https://github.com/${REPOSITORY}/actions/runs/${RUN_ID})
          - [Security Tab](https://github.com/${REPOSITORY}/security/code-scanning)
          - [CodeQL Results](https://github.com/${REPOSITORY}/security/code-scanning?tool=CodeQL)
          - [Trivy Results](https://github.com/${REPOSITORY}/security/code-scanning?tool=Trivy)
          
          ## 🛠️ Tools Information
          - **CodeQL:** Advanced static analysis for security vulnerabilities
          - **Trivy:** Comprehensive vulnerability scanner for containers and filesystems
          - **Super-Linter:** Multi-language linter for code quality and standards
          EOF
          
          # Create archive
          TIMESTAMP="$(date +%Y%m%d-%H%M%S)"
          ZIP_FILENAME="comprehensive-security-analysis-${TIMESTAMP}.zip"
          zip -r "$ZIP_FILENAME" scan-results/

      # ============================================================================
      # ARTIFACT UPLOAD
      # ============================================================================
      - name: Upload comprehensive security results
        if: always()
        uses: actions/upload-artifact@v4.6.2
        with:
          name: comprehensive-security-analysis
          path: comprehensive-security-analysis-*.zip
          retention-days: 30
          compression-level: 0
          if-no-files-found: ignore

      # ============================================================================
      # WORKFLOW SUMMARY
      # ============================================================================
      - name: Create workflow summary
        if: always()
        run: |
          echo "## 🔒 Comprehensive Security Analysis Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status | Details |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|---------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| 🔬 CodeQL Analysis | ${{ steps.codeql-analysis.outcome }} | Static security analysis |" >> $GITHUB_STEP_SUMMARY
          echo "| 🧹 Super-Linter | ${{ steps.super-linter.outcome }} | Code quality validation |" >> $GITHUB_STEP_SUMMARY
          
          # Check Trivy filesystem status
          if [ -f "trivy-results.sarif" ]; then
            echo "| 🛡️ Trivy Filesystem | ✅ success | Vulnerability scanning |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| 🛡️ Trivy Filesystem | ❌ failed | Vulnerability scanning |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "| 🔧 Trivy Config | ${{ steps.trivy-config.outcome }} | Configuration analysis |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📊 SARIF Files Generated" >> $GITHUB_STEP_SUMMARY
          
          # Check CodeQL SARIF
          if [ -f "codeql-results.sarif" ]; then
            echo "- **CodeQL SARIF:** ✅ Available" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **CodeQL SARIF:** ❌ Not generated" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check Trivy SARIF
          if [ -f "trivy-results.sarif" ]; then
            echo "- **Trivy SARIF:** ✅ Available" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Trivy SARIF:** ❌ Not generated" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📋 Quick Links" >> $GITHUB_STEP_SUMMARY
          echo "- [Security Tab](https://github.com/${{ github.repository }}/security/code-scanning)" >> $GITHUB_STEP_SUMMARY
          echo "- [Download Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY

      # ============================================================================
      # ISSUE MANAGEMENT - SEPARATE DETAILED ISSUES FOR EACH TOOL
      # ============================================================================
      - name: Create CodeQL Security Issues
        if: always() && steps.codeql-analysis.outcome == 'failure'
        uses: actions/github-script@v8.0.0
        with:
          script: |
            const currentDate = new Date().toISOString().split('T')[0];
            const analysisOutcome = '${{ steps.codeql-analysis.outcome }}';
            
            // Get CodeQL alerts for detailed reporting
            let codeqlFindings = "No specific findings data available through API in workflow context.";
            
            // Check if SARIF file exists for parsing
            const fs = require('fs');
            if (fs.existsSync('codeql-results.sarif')) {
              try {
                const sarif = JSON.parse(fs.readFileSync('codeql-results.sarif', 'utf8'));
                if (sarif.runs && sarif.runs[0] && sarif.runs[0].results) {
                  const results = sarif.runs[0].results;
                  if (results.length > 0) {
                    codeqlFindings = `## 🔬 CodeQL Findings (${results.length} issues)\n\n`;
                    results.slice(0, 10).forEach((result, index) => {
                      const ruleId = result.ruleId || 'Unknown Rule';
                      const message = result.message?.text || 'No description available';
                      const location = result.locations?.[0]?.physicalLocation?.artifactLocation?.uri || 'Unknown location';
                      const line = result.locations?.[0]?.physicalLocation?.region?.startLine || 'Unknown line';
                      
                      codeqlFindings += `### ${index + 1}. ${ruleId}\n`;
                      codeqlFindings += `- **Location:** \`${location}:${line}\`\n`;
                      codeqlFindings += `- **Description:** ${message}\n\n`;
                    });
                    if (results.length > 10) {
                      codeqlFindings += `*... and ${results.length - 10} more findings. Download the SARIF file for complete details.*\n\n`;
                    }
                  } else {
                    codeqlFindings = "✅ No security issues found by CodeQL analysis.";
                  }
                }
              } catch (error) {
                codeqlFindings = `❌ Error parsing CodeQL SARIF file: ${error.message}`;
              }
            }
            
            const issueTitle = '🔬 CodeQL Security Analysis Results';
            const issueBody = `# 🔬 CodeQL Static Security Analysis Report
            
            **Analysis Date:** ${currentDate}
            **Run ID:** ${context.runId}
            **Commit:** ${context.sha.substring(0, 8)}
            **Status:** ${analysisOutcome}
            
            ## 📊 Analysis Details
            - **Language:** JavaScript (with generic security patterns)
            - **Query Packs:** security-extended + security-and-quality
            - **Scope:** Shell scripts, configuration files, GitHub Actions workflows
            
            ${codeqlFindings}
            
            ## 🔗 Additional Resources
            - [Workflow Run](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            - [Security Tab (CodeQL)](https://github.com/${context.repo.owner}/${context.repo.repo}/security/code-scanning?tool=CodeQL)
            - [Download SARIF Results](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            
            *Auto-generated by CodeQL security analysis workflow*
            `;
            
            // Handle existing issues
            const existingIssues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: ['security', 'codeql']
            });
            
            const existingIssue = existingIssues.data.find(issue => 
              issue.title.includes('CodeQL Security Analysis Results')
            );
            
            if (existingIssue) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: `🔄 **Updated CodeQL Analysis - ${currentDate}**\n\n${issueBody}`
              });
            } else {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: issueTitle,
                body: issueBody,
                labels: ['security', 'codeql', 'automated-analysis']
              });
            }

      - name: Create Trivy Security Issues
        if: always() && hashFiles('trivy-results.sarif') != ''
        uses: actions/github-script@v8.0.0
        with:
          script: |
            const currentDate = new Date().toISOString().split('T')[0];
            
            // Parse Trivy SARIF results for detailed reporting
            let trivyFindings = "No Trivy findings data available.";
            let hasVulnerabilities = false;
            
            const fs = require('fs');
            if (fs.existsSync('trivy-results.sarif')) {
              try {
                const sarif = JSON.parse(fs.readFileSync('trivy-results.sarif', 'utf8'));
                if (sarif.runs && sarif.runs[0] && sarif.runs[0].results) {
                  const results = sarif.runs[0].results;
                  if (results.length > 0) {
                    hasVulnerabilities = true;
                    trivyFindings = `## 🛡️ Trivy Vulnerability Findings (${results.length} issues)\n\n`;
                    
                    // Group by severity
                    const bySeverity = results.reduce((acc, result) => {
                      const severity = result.level || 'unknown';
                      if (!acc[severity]) acc[severity] = [];
                      acc[severity].push(result);
                      return acc;
                    }, {});
                    
                    Object.entries(bySeverity).forEach(([severity, findings]) => {
                      const emoji = severity === 'error' ? '🔴' : severity === 'warning' ? '🟡' : '🔵';
                      trivyFindings += `### ${emoji} ${severity.toUpperCase()} (${findings.length} issues)\n\n`;
                      
                      findings.slice(0, 5).forEach((result, index) => {
                        const ruleId = result.ruleId || 'Unknown CVE';
                        const message = result.message?.text || 'No description available';
                        const location = result.locations?.[0]?.physicalLocation?.artifactLocation?.uri || 'Unknown location';
                        
                        trivyFindings += `**${index + 1}. ${ruleId}**\n`;
                        trivyFindings += `- **Location:** \`${location}\`\n`;
                        trivyFindings += `- **Details:** ${message.substring(0, 200)}${message.length > 200 ? '...' : ''}\n\n`;
                      });
                      
                      if (findings.length > 5) {
                        trivyFindings += `*... and ${findings.length - 5} more ${severity} findings.*\n\n`;
                      }
                    });
                  } else {
                    trivyFindings = "✅ No vulnerabilities found by Trivy filesystem scan.";
                  }
                }
              } catch (error) {
                trivyFindings = `❌ Error parsing Trivy SARIF file: ${error.message}`;
              }
            }
            
            // Only create or update issues if vulnerabilities were actually found
            if (!hasVulnerabilities) {
              console.log('✅ No Trivy vulnerabilities found - skipping issue creation');
              return;
            }
            
            const issueTitle = '🛡️ Trivy Vulnerability Analysis Results';
            const issueBody = `# 🛡️ Trivy Security Vulnerability Report
            
            **Analysis Date:** ${currentDate}
            **Run ID:** ${context.runId}
            **Commit:** ${context.sha.substring(0, 8)}
            **Scan Type:** Filesystem vulnerability scanning
            
            ## 📊 Analysis Summary
            - **Scan Scope:** Complete repository filesystem
            - **Focus:** Dependencies, container images, known vulnerabilities
            - **Database:** Latest vulnerability definitions
            
            ${trivyFindings}
            
            ## 🔧 Remediation Steps
            1. **Review each vulnerability** listed above for impact assessment
            2. **Update dependencies** to fixed versions where available
            3. **Apply security patches** to vulnerable packages
            4. **Re-run analysis** to verify fixes
            
            ## 🔗 Additional Resources
            - [Workflow Run](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            - [Security Tab (Trivy)](https://github.com/${context.repo.owner}/${context.repo.repo}/security/code-scanning?tool=Trivy)
            - [Download SARIF Results](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            
            *Auto-generated by Trivy vulnerability analysis workflow*
            `;
            
            // Handle existing issues
            const existingIssues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: ['security', 'trivy']
            });
            
            const existingIssue = existingIssues.data.find(issue => 
              issue.title.includes('Trivy Vulnerability Analysis Results')
            );
            
            if (existingIssue) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: `🔄 **Updated Trivy Analysis - ${currentDate}**\n\n${issueBody}`
              });
            } else {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: issueTitle,
                body: issueBody,
                labels: ['security', 'trivy', 'automated-analysis', 'vulnerability']
              });
            }

      - name: Create Super-Linter Issues
        if: always() && steps.super-linter.outcome == 'failure'
        uses: actions/github-script@v8.0.0
        with:
          script: |
            const currentDate = new Date().toISOString().split('T')[0];
            const fs = require('fs');
            const superLinterOutcome = '${{ steps.super-linter.outcome }}';
            
            // Parse Super-Linter logs for specific error details
            let linterFindings = "";
            let hasIssues = true; // We know it failed
            
            // Check for captured logs
            const logDir = 'super-linter-output';
            let specificFindings = [];
            
            if (fs.existsSync(logDir)) {
              console.log('Found super-linter-output directory');
              
              // Read summary file if it exists
              const summaryFile = `${logDir}/summary.md`;
              if (fs.existsSync(summaryFile)) {
                const summaryContent = fs.readFileSync(summaryFile, 'utf8');
                linterFindings += `## 📋 Detailed Findings\n\n${summaryContent}\n\n`;
              }
              
              // Process individual log files
              const logFiles = fs.readdirSync(logDir).filter(file => 
                file.endsWith('.log') || file.endsWith('.tap') || file.endsWith('.txt')
              );
              
              if (logFiles.length > 0) {
                linterFindings += `## 🔍 Individual Linter Results\n\n`;
                
                for (const logFile of logFiles.slice(0, 5)) { // Limit to first 5 files
                  try {
                    const logPath = `${logDir}/${logFile}`;
                    const logContent = fs.readFileSync(logPath, 'utf8');
                    
                    // Extract meaningful error lines
                    const lines = logContent.split('\n');
                    const errorLines = lines.filter(line => 
                      line.includes('ERROR') || 
                      line.includes('FAIL') || 
                      line.includes('SC') || // ShellCheck codes
                      line.includes('DL') || // Hadolint codes
                      line.includes('MD') || // Markdownlint codes
                      line.includes('not ok')
                    ).slice(0, 10); // Limit to 10 errors per file
                    
                    if (errorLines.length > 0) {
                      linterFindings += `### ${logFile}\n`;
                      linterFindings += `\`\`\`\n${errorLines.join('\n')}\`\`\`\n\n`;
                      
                      // Parse specific error patterns
                      errorLines.forEach(line => {
                        // ShellCheck errors
                        const shellCheckMatch = line.match(/In (.+) line (\d+):/);
                        if (shellCheckMatch) {
                          specificFindings.push({
                            tool: 'ShellCheck',
                            file: shellCheckMatch[1],
                            line: shellCheckMatch[2],
                            message: line
                          });
                        }
                        
                        // Hadolint errors
                        const hadolintMatch = line.match(/(Dockerfile):(\d+) (DL\d+)/);
                        if (hadolintMatch) {
                          specificFindings.push({
                            tool: 'Hadolint',
                            file: hadolintMatch[1],
                            line: hadolintMatch[2],
                            code: hadolintMatch[3],
                            message: line
                          });
                        }
                        
                        // Markdownlint errors
                        const markdownMatch = line.match(/(.+\.md):(\d+) (MD\d+)/);
                        if (markdownMatch) {
                          specificFindings.push({
                            tool: 'Markdownlint',
                            file: markdownMatch[1],
                            line: markdownMatch[2],
                            code: markdownMatch[3],
                            message: line
                          });
                        }
                      });
                    }
                  } catch (error) {
                    console.log(`Error reading ${logFile}: ${error.message}`);
                  }
                }
              }
            }
            
            // Create structured findings summary
            if (specificFindings.length > 0) {
              const groupedFindings = specificFindings.reduce((acc, finding) => {
                if (!acc[finding.tool]) acc[finding.tool] = [];
                acc[finding.tool].push(finding);
                return acc;
              }, {});
              
              linterFindings += `## 🎯 Summary by Tool\n\n`;
              
              for (const [tool, findings] of Object.entries(groupedFindings)) {
                linterFindings += `### ${tool} (${findings.length} issues)\n\n`;
                findings.slice(0, 5).forEach((finding, index) => {
                  linterFindings += `${index + 1}. **${finding.file}:${finding.line}**\n`;
                  if (finding.code) linterFindings += `   - Code: \`${finding.code}\`\n`;
                  linterFindings += `   - Issue: \`${finding.message.trim()}\`\n\n`;
                });
                if (findings.length > 5) {
                  linterFindings += `   *... and ${findings.length - 5} more issues*\n\n`;
                }
              }
            }
            
            // Fallback to generic guidance if no specific logs found
            if (!linterFindings.trim()) {
              linterFindings = `## 🔧 Super-Linter Issues Detected\n\n`;
              linterFindings += `Super-Linter detected code quality issues. View the [workflow logs](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) for detailed information.\n\n`;
              
              // Add common issue categories as before
              linterFindings += `### 📝 Common Issue Categories\n\n`;
              linterFindings += `**Shell Script Issues (shellcheck):**\n`;
              linterFindings += `- Unquoted variables that may cause word splitting\n`;
              linterFindings += `- Missing error handling (\`set -e\` or \`|| exit 1\`)\n`;
              linterFindings += `- Unsafe command substitution patterns\n`;
              linterFindings += `- Variable assignments that may fail silently\n\n`;
              
              linterFindings += `**Dockerfile Issues (hadolint):**\n`;
              linterFindings += `- Missing \`--no-cache-dir\` in pip install commands\n`;
              linterFindings += `- Using \`ADD\` instead of \`COPY\` for local files\n`;
              linterFindings += `- Missing version pinning in package installations\n`;
              linterFindings += `- Inefficient layer management\n\n`;
              
              linterFindings += `**Markdown Issues (markdownlint):**\n`;
              linterFindings += `- Missing or inconsistent heading structure\n`;
              linterFindings += `- Trailing whitespace at line endings\n`;
              linterFindings += `- Missing blank lines around headers\n`;
              linterFindings += `- Line length violations\n\n`;
              
              linterFindings += `**YAML/JSON Issues:**\n`;
              linterFindings += `- Indentation inconsistencies\n`;
              linterFindings += `- Missing or extra commas/colons\n`;
              linterFindings += `- Trailing whitespace\n`;
              linterFindings += `- Syntax errors or malformed structures\n\n`;
            }
            
            // Add file-specific guidance  
            linterFindings += `### 🎯 Files Likely Affected\n\n`;
            linterFindings += `Based on your repository structure, check these files:\n`;
            linterFindings += `- \`root/\` directory - Shell scripts and configuration\n`;
            linterFindings += `- \`scripts/\` directory - Utility scripts\n`;
            linterFindings += `- \`Dockerfile\` - Container configuration\n`;
            linterFindings += `- \`*.md\` files - Documentation\n`;
            linterFindings += `- \`.github/workflows/\` - YAML workflow files\n\n`;
            
            const issueTitle = '🧹 Super-Linter Code Quality Issues';
            const issueBody = `# 🧹 Super-Linter Code Quality Report
            
            **Analysis Date:** ${currentDate}
            **Run ID:** ${context.runId}
            **Commit:** ${context.sha.substring(0, 8)}
            **Status:** ${superLinterOutcome}
            
            ## 📊 Analysis Summary
            
            **Languages Analyzed:**
            - ✅ Bash scripts (shellcheck)
            - ✅ Dockerfile (hadolint)  
            - ✅ Markdown files (markdownlint)
            - ✅ JSON files (jsonlint)
            - ✅ YAML files (yamllint)
            
            ${linterFindings}
            
            ## 🔧 Step-by-Step Remediation
            
            ### 1. 📋 Review Detailed Logs
            \`\`\`bash
            # View the full workflow logs for specific file/line errors
            gh run view ${context.runId} --log
            \`\`\`
            
            ### 2. 🛠️ Local Development Setup
            \`\`\`bash
            # Install local linting tools
            npm install -g markdownlint-cli
            pip install yamllint
            
            # For shellcheck (Linux/macOS)
            # Ubuntu/Debian: apt-get install shellcheck
            # macOS: brew install shellcheck
            
            # For hadolint (Dockerfile linting)
            # Download from: https://github.com/hadolint/hadolint/releases
            \`\`\`
            
            ### 3. 🧪 Run Local Validation
            \`\`\`bash
            # Check specific file types
            find . -name "*.sh" -exec shellcheck {} \\;
            hadolint Dockerfile
            markdownlint *.md
            yamllint .github/workflows/*.yml
            \`\`\`
            
            ### 4. ✅ Test Before Committing
            \`\`\`bash
            # Run Super-Linter locally (optional)
            docker run --rm -v "\\$(pwd)":/tmp/lint \\\\
              -e DEFAULT_BRANCH=master \\\\
              -e RUN_LOCAL=true \\\\
              github/super-linter:latest
            \`\`\`
            
            ## 🔗 Additional Resources
            - [Workflow Run with Detailed Logs](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            - [Super-Linter Documentation](https://github.com/super-linter/super-linter)
            - [Shellcheck Wiki](https://github.com/koalaman/shellcheck/wiki)
            - [Hadolint Rules](https://github.com/hadolint/hadolint#rules)
            - [Markdownlint Rules](https://github.com/DavidAnson/markdownlint/blob/main/doc/Rules.md)
            
            ## ⚡ Quick Fixes for Common Issues
            
            **Shell Scripts:**
            \`\`\`bash
            # Quote variables
            echo "\\$variable" instead of echo \\$variable
            
            # Add error handling
            set -euo pipefail  # at top of script
            \`\`\`
            
            **Dockerfile:**
            \`\`\`dockerfile
            # Use specific versions
            FROM node:18-alpine instead of FROM node:latest
            
            # Combine RUN commands
            RUN apt-get update && apt-get install -y package && rm -rf /var/lib/apt/lists/*
            \`\`\`
            
            **Markdown:**
            \`\`\`markdown
            # Add blank lines around headers
            
            ## Header
            
            Content here
            \`\`\`
            
            *Auto-generated by Super-Linter code quality analysis workflow*
            `;
            
            // Handle existing issues
            const existingIssues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: ['code-quality', 'super-linter']
            });
            
            const existingIssue = existingIssues.data.find(issue => 
              issue.title.includes('Super-Linter Code Quality Issues')
            );
            
            if (existingIssue) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: `🔄 **Updated Super-Linter Analysis - ${currentDate}**\n\n${issueBody}`
              });
            } else {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: issueTitle,
                body: issueBody,
                labels: ['code-quality', 'super-linter', 'automated-analysis']
              });
            }
